<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>

	<meta http-equiv="content-type" content="text/html; charset=utf-8" />
	<meta name="description" content="RJCP est une conf&eacute;rence organis&eacute;e par des doctorants pour des jeunes chercheurs (Master 2, doctorants, post-docs, ATER...)." />
	<meta name="keywords" content="rjcp, rjcp2009 avignon, rjcp 2009 avignon, stic, sciences technologie information communication, conf&eacute;rence, manifestation, jeune cherche, doctorant " />
	<meta name="robots" content="index, follow, all" />
	<meta name="language" content="fr" />

	<title>RJCP 2009 Avignon</title>
	
		<script type="text/javascript" src="js/mootools-1.2.1-core-yc.js"></script>
		<script type="text/javascript" src="js/mootools-1.2-more.js"></script>		
		
		<!--[if IE]>
		<script type="text/javascript" src="js/minmax.js"></script>
		<![endif]-->
		
		
		<script type="text/javascript">
		var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." : "http://www.");
		document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));
		</script>
		<script type="text/javascript">
		try {
		var pageTracker = _gat._getTracker("UA-7573503-1");
		pageTracker._trackPageview();
		
		
		function changeFontSize(inc)
		{
			var elementsToChangeFontSize = new Array('body', 'h1', 'h2', 'h3', 'ul', 'li', 'p', 'th');
			for (i=0; i < elementsToChangeFontSize.length; i++) {
				var p = document.getElementsByTagName(elementsToChangeFontSize[i]);
				for(n=0; n<p.length; n++) {	
					if(p[n].style.fontSize) {
						var size = parseInt(p[n].style.fontSize.replace("px", ""));
						p[n].style.fontSize = size+inc + 'px';
					}
					else {
						
					} 
			   }
			}
		}
		
		} catch(err) {}</script>
	
		<link href="css/style.css" rel="stylesheet" type="text/css" media="screen" />

	</head>
<body>

<map name="map">
 <area shape="rect" coords="63,240,213,286" href="session_1.html" />
 <area shape="rect" coords="62,315,211,359" href="session_2.html" />
 <area shape="rect" coords="264,120,414,166" href="session_3.html" />
 <area shape="rect" coords="265,194,413,240" href="session_4.html" />
 <area shape="rect" coords="466,210,615,258" href="session_5.html" />
 <area shape="rect" coords="63,174,211,210" href="invites.html#jeanneret" />
 <area shape="rect" coords="264,316,362,354" href="invites.html#beaugendre" />
 <area shape="rect" coords="466,144,615,181" href="invites.html#rossato" />
</map>

  <!-- begin #wrapper_header -->
  <div id="wrapper_header">

    <!-- begin #header -->
	<div id="header">
		<a href="../index.html" class="simple_link">
			<img src="images/MajecSTIC2009.png" alt="Majecstic2009" title="RJCP 2009 &agrave; Avignon" id="date_conf" width="255px" />

		</a>
	</div>
    <!-- end #header -->


  <div id="wrapper">
    <div id="page">
    
      
		<div id="wrapper_sidebar">
			<div id="sidebar">
        
				<ul>
				<li><a href="index.html" class='simple_link'>Pr&eacute;sentation</a></li>
				<li><a href="edito.html" class='simple_link'>Message des organisateurs</a></li>
				<li><a href="comites.html" class='simple_link'>Comit&eacute;s</a></li>
				<li><a href="files/Programme_et_recueil_des_resumes_RJCP.pdf" class='simple_link'>Programme [PDF]</a></li>
				<li><a href="invites.html" class='simple_link'>Conf&eacute;rences invit&eacute;es</a></li>
				<li><a href="sessions.html" class='simple_link'>Index des sessions</a></li>
				<li><a href="topics.html" class='simple_link'>Index des th&eacute;matiques</a></li>
				<li><a href="auteurs.html" class='simple_link'>Index des auteurs</a></li>
				<li><a href="articles.html" class='simple_link'>Tous les articles</a></li>
				<li><a href="stats.html" class='simple_link'>Statistiques</a></li>
				<li><a href="logiciels/liens.html" class='simple_link'>Logiciels Audio</a></li>
				<li><a href="http://rjcp2009.univ-avignon.fr/actes.php" class='simple_link'>Actes en ligne</a></li>
				</ul>  
			</div>

			<div class="submenu">

			<div class="logo_nplia">
			<br/>Manifestation support&eacute;e par l'<strong>association <abbr title="Non Permanents du Laboratoire Informatique d'Avignon">NP-LIA</addr></strong><br/>

			<a href="http://www.np-lia.fr/" class="simple_link"><img src="images/np-lia_v_claire.png" alt="Non Permanents du Laboratoire Informatique d'Avignon" title="Non Permanents du Laboratoire Informatique d'Avignon" width="160px"/></a><br/>
			NP-LIA organise <a href="../MajecSTIC/index.html" class="simple_link">MajecSTIC</a> parallèlement aux <abbr title="Rencontres Jeunes Chercheurs en Parole">RJCP</abbr>.
			</div>

			</div>
		</div>
    
		<div id="content">

				<div class="post">
					<h2 class="title">Session Orale O3</h2>
					<div class="entry">
						<ul>
						<li><strong>Titre : Phonétique</strong></li>
						<li><strong>Pr&eacute;sidente : </strong>Christine Meunier</li>
						<li><strong>Date : </strong>Mardi 17/11 de 9h45 à 12h05</li>
						</ul>
					</div>
				</div>
	
	
							<div class="post">
								<a name="112"></a><h2 class="title">Article 112</h2>
								<div class="entry">
								<ul>
									<li><strong>Titre : <font color="red">Identification des consonnes finales du vietnamien par des locuteurs natifs</font></strong></li>
						<li><strong>Thi-Thuy-Hien Tran </strong> (Département Parole et Cognition de GIPSA-lab)</li>					<li><strong>Nathalie Vallée </strong> (Département Parole et Cognition de GIPSA-lab)</li>
									<li><strong>R&eacute;sum&eacute; : </strong> A great difficulty encountered by Vietnamese subjects, who learn French, is that consonant clusters, which do not exist in Vietnamese, are mispronounced. This problem persists even after several years of practicing, and even when the French clusters correspond to Vietnamese consonant sequences. The general aim of our project is to identify the factors which are the main cause of this problem. In this paper, we examine the perception of syllable-final stops (/p/, /t/, /k/, /m/, /n/, /&#x014B;/) in Vietnamese by 20 native Northern-Vietnamese listeners. Our findings suggest that specific acoustic characteristics and probably the lexical frequency of final consonants lead the subjects in their choice of responses.</li>
									<li><a href="articles/112.pdf">Voir l'article entier</a></li>
								</ul>
								</div>
							</div>
				
				
							<div class="post">
								<a name="222"></a><h2 class="title">Article 222</h2>
								<div class="entry">
								<ul>
									<li><strong>Titre : <font color="red">Caractérisation automatique des accents étrangers</font></strong></li>
						<li><strong>Abdelkarim Mars </strong> (Laboratoire d'informatique de grenoble)</li>
									<li><strong>R&eacute;sum&eacute; : </strong> Parmi les phénomènes qui affectent la manière dont nous parlons, l’accent est une des composantes principales de la variation observée. La prononciation d’un locuteur peut en effet nous renseigner sur son origine, géographique et sociale. La description des caractéristiques phonétiques qui sous-tendent les différences d’accent perçues constitue donc un intérêt scientifique particulier. De plus, la recherche dans le domaine des accents contribue a l’amélioration d’applications technologiques telles que la reconnaissance de la parole et l’indexation du locuteur.  Ce papier propose une étude phonétique acoustique des accents étrangers en français. Afin d’analyser à grande échelle les variations liées a l’origine de locuteur, nous avons évalue l’apport des outils automatiques décodage acoustico-phonétique et alignement force.</li>
									<li><a href="articles/222.pdf">Voir l'article entier</a></li>
								</ul>
								</div>
							</div>
				
				
							<div class="post">
								<a name="232"></a><h2 class="title">Article 232</h2>
								<div class="entry">
								<ul>
									<li><strong>Titre : <font color="red">Une Base de données Etiquetée Formantiquement en Langue Arabe Standard</font></strong></li>
						<li><strong>Imen Jemaa </strong> (Unité de Recherche Traiement du Signal, Traitement de l'image et Reconnaissance de Formes, Tunisie)</li>					<li><strong>Oussama Rekhis </strong> (Unité de Recherche Traiement du Signal, Traitement de l'image et Reconnaissance de Formes, Tunisie)</li>					<li><strong>Kais Ouni </strong> (Unité de Recherche Traiement du Signal, Traitement de l'image et Reconnaissance de Formes, Tunisie)</li>					<li><strong>Yves Laprie </strong> (Equipe Parole, LORIA Nancy1, France)</li>
									<li><strong>R&eacute;sum&eacute; : </strong> While formant frequencies are known to play a critical role in human speech perception and in computer speech processing, there has been a lack of standard databases needed for the quantitative evaluation of automatic formant extraction techniques especially in Arabic language. We report in this paper our recent effort to create a reference database of the first three formant tracks. The manually Formant labeling is carried out used the Winsnoori tool. Furthermore, we present in this paper an exploratory use of the database to quantitatively evaluate the automatic LPC method implemented in the popular open source Praat using the hand edited formant trajectories as reference. </li>
									<li><a href="articles/232.pdf">Voir l'article entier</a></li>
								</ul>
								</div>
							</div>
				
				
							<div class="post">
								<a name="242"></a><h2 class="title">Article 242</h2>
								<div class="entry">
								<ul>
									<li><strong>Titre : <font color="red">Construction d’un corpus robuste de différents dialectes arabes</font></strong></li>
						<li><strong>Mohamed Belgacem </strong> (Laboratoire LIDILEM )</li>
									<li><strong>R&eacute;sum&eacute; : </strong> Notre article s’intègre dans le cadre du projet intitulé 'Oréodule' : un système embarqué temps réel de reconnaissance, de traduction et de synthèse de la parole arabe. L’objet de notre intérêt dans cet article est la présentation d’un corpus vocal de la parole arabe. Nous détaillerons les étapes de constitution de ce corpus et les difficultés rencontrées lors de son élaboration. Nous intègrerons également les différents résultats pratiques obtenus lors de chaque phase (tailles des enregistrements, volume total du notre corpus, etc.).</li>
									<li><a href="articles/242.pdf">Voir l'article entier</a></li>
								</ul>
								</div>
							</div>
				
				
							<div class="post">
								<a name="92"></a><h2 class="title">Article 92</h2>
								<div class="entry">
								<ul>
									<li><strong>Titre : <font color="red">Perception d’expressions multimodales du Feeling of Thinking  (états mentaux et affectifs, intentions, attitudes) en interaction </font></strong></li>
						<li><strong>Anne Vanpé </strong> (GIPSA-lab, Département Parole et Cognition (ex-ICP), UMR 5216 CNRS/Université de Grenoble)</li>					<li><strong>Véronique Aubergé </strong> (GIPSA-lab, Département Parole et Cognition (ex-ICP), UMR 5216 CNRS/Université de Grenoble)</li>
									<li><strong>R&eacute;sum&eacute; : </strong> Human-Machine Interaction, as interaction between two humans, can be considered as a dynamic process where the human is continuously communicating, even when he is “expressively” listening (informative backchannel and feedback). The present study analyses the audio-visual non speech expressions for two subjects in spontaneous HMI corpora, following an ethology-based methodology. First results reveal a large panel of values expressed outside of turns (e.g. mental states, intentions, attitudes, emotions) that we have globally called Feeling of Thinking. We have shown the role of static vs. dynamic processing of visual information and we are now attempting to investigate some specific non speech “vocal events”. Their temporal distribution seems to be particularly relevant for the perception of Feeling of Thinking expressions.</li>
									<li><a href="articles/92.pdf">Voir l'article entier</a></li>
								</ul>
								</div>
							</div>
				
				
			
			
		</div>
		
		
	
		<!-- end #sidebar -->
		<div style="clear: both;">&nbsp;</div>
	</div>

	<!-- end #page -->
</div>


	<div id="footer">
    

		<p><a href="http://www.univ-avignon.fr" title="Universit&eacute; d'Avignon et des Pays de Vaucluse">Universit&eacute; d'Avignon</a> 
		| 
		<a href="http://www.lia.univ-avignon.fr" title="Laboratoire Informatique d'Avignon">Laboratoire Informatique d'Avignon</a>
		| 
		<a href="http://www.univ-avignon.fr/fr/recherche/laboratoires/strlab/structure/laboratoire-culture-et-communication-ea-3151.html" title="Laboratoire Culture et Communication">Laboratoire Culture et Communication</a>
		</p>
		<p>
		<!--
		  <a href="http://www.univ-avignon.fr" class="simple_link" title="Universit&eacute; d'Avignon et des Pays de Vaucluse"><img src="./images/logo_uapv.png" /></a> <a href="http://www.lia.univ-avignon.fr"   class="simple_link" title="Laboratoire Informatique d'Avignon"><img src="./images/logo_lia.png" /></a> <a href="http://www.univ-avignon.fr/fr/recherche/laboratoires/strlab/structure/laboratoire-culture-et-communication-ea-3151.html"><img src="./images/logo_lcc.png" /></a>
		  -->
		  
		<a href="http://www.univ-avignon.fr" class="simple_link" title="Universit&eacute; d'Avignon et des Pays de Vaucluse"><img src="images/logo_uapv.png" /></a>
		<a href="http://www.lia.univ-avignon.fr" class="simple_link" title="Laboratoire Informatique d'Avignon"><img src="images/logo_lia.png" /></a>
		<a href="http://www.edi2s.univ-montp2.fr/" class="simple_link" title="Ecole Doctorale Information Structures Systèmes"><img src="images/i2s.png" /></a>
		<br/>

		<a href="http://www.univ-avignon.fr/fr/recherche/laboratoires/strlab/structure/laboratoire-culture-et-communication-ea-3151.html" class="simple_link" title="Laboratoire Culture et Communication"><img src="images/logo_lcc.png" /> </a>
		</p>
			</div>

	<!-- end #footer -->
  </div>

</body>
</html>
